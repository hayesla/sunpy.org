{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. post:: 3 April 2024\n",
    "   :author: Stuart Mumford\n",
    "   :tags: eclipse, outreach, tutorials\n",
    "   :category: Tutorial\n",
    "   :exclude:\n",
    "\n",
    "   On 8 April 2024, a total solar eclipse will pass over Mexico, the United States, and Canada, allowing millions of people to see the highly-structured solar corona with their own eyes. Along the path of totality, many will be taking their own pictures of the eclipse. In this post we demonstrate how you can use SunPy to process your own eclipse photos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Process Your Solar Eclipse Photos with SunPy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "On April 8th, 2024, [a total solar eclipse will pass over North America](https://science.nasa.gov/eclipses/).\n",
    "A total solar eclipse happens when the Moon passes between the Sun and Earth, completely blocking the face of the Sun.\n",
    "Only during totality, when the bright disk is completely obscured, is it possible to see with the naked eye the solar corona, the outermost layer of the Sun's atmosphere.\n",
    "The total solar eclipse will give millions across North America the chance to see and photograph the solar corona.\n",
    "\n",
    "In this blog post, we will show how you can use SunPy to process your photos of the eclipse.\n",
    "To do this, we will use an image from the 2017 solar eclipse that also passed over North America, the so-called \"Great American Eclipse\".\n",
    "We will walk through processing this image with SunPy as well as other Python libraries, so that you can generate a coordinate system for your image.\n",
    "As we will show, this allows you to combine your eclipse images with solar observations such as those from NASA's *Solar Dynamics Observatory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "import exifread\n",
    "import matplotlib.image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sunpy.coordinates\n",
    "import sunpy.coordinates.sun\n",
    "from astropy.constants import R_earth\n",
    "from astropy.coordinates import CartesianRepresentation, EarthLocation, SkyCoord\n",
    "\n",
    "# We have defined a few helper functions in this `eclipse_helpers.py` file.\n",
    "from eclipse_helpers import SOLAR_ECLIPSE_IMAGE, get_camera_metadata\n",
    "from matplotlib.patches import Circle\n",
    "from scipy import ndimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from sunpy.map.header_helper import make_fitswcs_header\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.time import parse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Read in Your Eclipse Photo\n",
    "\n",
    "The first step is to read in our image.\n",
    "As mentioned above, we will be using an image taken during the 2017 eclipse taken with a consumer-grade camera.\n",
    "When reading in our image data, we'll invert the y-axis and convert it to a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rgb = np.flipud(matplotlib.image.imread(SOLAR_ECLIPSE_IMAGE))\n",
    "im = rgb2gray(im_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, origin=\"lower\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "In order to be able to align our image with solar images from NASA, we will also need some additional metadata from our image.\n",
    "The two most important things we need to know are:\n",
    "\n",
    "1. the GPS coordinates of where the photo was taken and\n",
    "2. the time the image was taken\n",
    "\n",
    "We can pull this metadata from the file and then use an additional function we wrote to process this metadata into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(SOLAR_ECLIPSE_IMAGE).open(\"rb\") as f:\n",
    "    tags = exifread.process_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = get_camera_metadata(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "As it turns out, the time on the camera used to take this eclipse photo was wrong, we have to manually correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata[\"time\"] = parse_time(\"2017-08-21 17:27:13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Find the Moon\n",
    "\n",
    "Now that we've loaded our image and accompanying metadata, the next step is to locate the edge of the Moon in our image.\n",
    "This allows us to find the center of the Moon, which is needed when aligning our data, as well as allowing us to determine the scale of the Moon in the image.\n",
    "In order to do this we are going to use several different image manipulation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "\n",
    "We start with applying a [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_filter) to help segment the lunar disk from the corona and mask all parts of the image above a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_im = ndimage.gaussian_filter(im, 8)\n",
    "mask = blur_im > blur_im.mean() * 3\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We then label those masked regions and select only the parts of the image that correspond to the bright, diffuse corona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_im, nb_labels = ndimage.label(mask)\n",
    "slice_y, slice_x = ndimage.find_objects(label_im == 1)[0]\n",
    "roi = blur_im[slice_y, slice_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The next step is to detect the inner edge of the bright corona.\n",
    "To do this, we apply a [Sobel filter](https://en.wikipedia.org/wiki/Sobel_operator) in both the x and y directions, and then calculate a single image from the two directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = ndimage.sobel(roi, axis=1, mode=\"constant\")\n",
    "sy = ndimage.sobel(roi, axis=0, mode=\"constant\")\n",
    "sob = np.hypot(sx, sy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Finally, we use scikit-image to apply the [Hough Transform](https://en.wikipedia.org/wiki/Hough_transform) to identify circles in the image.\n",
    "We then use this to extract the size in pixels of the lunar disk and its center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_radii = np.arange(np.floor(np.mean(sob.shape) / 4), np.ceil(np.mean(sob.shape) / 2), 10)\n",
    "hough_res = hough_circle(sob > (sob.mean() * 5), hough_radii)\n",
    "\n",
    "# Select the most prominent circle\n",
    "accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, total_num_peaks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "As shown below, we now have a list of pixel coordinates corresponding to the solar limb in our image.\n",
    "The first frame is the cropped original image.\n",
    "The middle frame is the Sobel filtered image used to apply the Hough transform.\n",
    "The right frame is the fitted circle on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(9.5, 6))\n",
    "ax[0].imshow(im[slice_y, slice_x])\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(sob > (sob.mean() * 5))\n",
    "ax[1].set_title(\"Sobel\")\n",
    "circ = Circle(\n",
    "    [cx, cy], radius=radii, facecolor=\"none\", edgecolor=\"red\", linewidth=2, linestyle=\"dashed\", label=\"Hough fit\"\n",
    ")\n",
    "ax[2].imshow(im[slice_y, slice_x])\n",
    "ax[2].add_patch(circ)\n",
    "ax[2].set_title(\"Original with fit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Lastly, let's add units to our circle that we fit the lunar limb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cx = (cx[0] + slice_x.start) * u.pix\n",
    "im_cy = (cy[0] + slice_y.start) * u.pix\n",
    "im_radius = radii[0] * u.pix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Make a SunPy `Map`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "At this point, we have our image data, it's metadata and we've located the Moon.\n",
    "Now we are ready to load our eclipse photograph into a SunPy `Map`!\n",
    "A `Map` allows us to carry around both the data and metadata of our image together and, importantly, makes it easy to combine solar observations from multiple observatories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "First, we define the observer location (i.e., where on Earth did we take our picture?) and the orientation of the Sun in the sky.\n",
    "For the observer location, we can use the GPS coordinates from our image metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = EarthLocation(lat=camera_metadata[\"gps\"][0], lon=camera_metadata[\"gps\"][1], height=camera_metadata[\"gps\"][2])\n",
    "observer = loc.get_itrs(camera_metadata[\"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Second, we determine the [angular size](https://en.wikipedia.org/wiki/Angular_diameter) of the Moon using its radius and its distance from the observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "moon = SkyCoord(sunpy.coordinates.get_body_heliographic_stonyhurst(\"moon\", camera_metadata[\"time\"], observer=observer))\n",
    "R_moon = 0.2725076 * R_earth  # IAU mean radius\n",
    "dist_moon = SkyCoord(observer).separation_3d(moon)\n",
    "moon_obs = np.arcsin(R_moon / dist_moon).to(\"arcsec\")\n",
    "print(moon_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Combining this angular radius with the radius of the lunar disk in pixels gives us the angular size of the pixels in the image.\n",
    "In the parlance of astronomical imaging, this is often referred to as the *plate scale*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_scale = moon_obs / im_radius\n",
    "print(plate_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We also use the observer location to calculate the orientation of the Sun as seen from that location on Earth.\n",
    "This gives us a rotation angle between our image coordinate system and the solar north pole.\n",
    "If your camera is not perfectly horizontal then you may need to fudge this value slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_rotation_angle = sunpy.coordinates.sun.orientation(loc, camera_metadata[\"time\"])\n",
    "print(solar_rotation_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Finally we have all the information we need to build a sunpy `Map` for our eclipse image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = sunpy.coordinates.Helioprojective(observer=observer, obstime=camera_metadata[\"time\"])\n",
    "moon_hpc = moon.transform_to(frame)\n",
    "\n",
    "header = make_fitswcs_header(\n",
    "    im,\n",
    "    moon_hpc,\n",
    "    reference_pixel=u.Quantity([im_cx, im_cy]),\n",
    "    scale=u.Quantity([plate_scale, plate_scale]),\n",
    "    rotation_angle=solar_rotation_angle,\n",
    "    exposure=camera_metadata.get(\"exposure_time\"),\n",
    "    instrument=camera_metadata.get(\"camera_model\"),\n",
    "    observatory=camera_metadata.get(\"author\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_map = sunpy.map.Map(im, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(projection=eclipse_map)\n",
    "eclipse_map.plot(axes=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Find a Star\n",
    "\n",
    "Though we already have all of the metadata we need to make a SunPy `Map`, we can further improve the accuracy by \n",
    "locating a known star in the image and using that to determine the rotation angle.\n",
    "In the case of the 2017 eclipse the very bright star (magnitude 1.4) [Regulus](https://en.wikipedia.org/wiki/Regulus) was close to the Sun and in the field of view of our photograph.\n",
    "For the 2024 eclipse, no such bright star will be visible, which may make this method of aligning your image challenging.\n",
    "The best candidate looks to be [Alpha Piscium](https://en.wikipedia.org/wiki/Alpha_Piscium) which is a binary system with a combined magnitude of 3.82, significantly dimmer than Regulus.\n",
    "You can see the stars close to the Sun by using [Stellarium](https://stellarium-web.org/skysource/Sun?fov=1.1092&amp;date=2024-04-08T18:30:47Z&amp;lat=28.86&amp;lng=-100.53&amp;elev=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "As Regulus is a well known star, we can create a coordinate object for it, including its distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulus = SkyCoord(ra=\"10h08m22.311s\", dec=\"11d58m01.95s\", distance=79.3 * u.lightyear, frame=\"icrs\")\n",
    "print(regulus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We can then plot the expected location of Regulus on our eclipse image.\n",
    "We set the scaling such that it make Regulus more visible and zoom in on the relevant part of the field of view.\n",
    "You can see that the expected location and the actual location are quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(projection=eclipse_map)\n",
    "eclipse_map.plot(axes=ax, clip_interval=(0, 90) * u.percent)\n",
    "ax.plot_coord(\n",
    "    regulus, \"o\", markeredgewidth=0.5, markeredgecolor=\"w\", markerfacecolor=\"None\", markersize=10, label=\"Regulus\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlim(100, 500)\n",
    "plt.ylim(0, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Given this offset, we want to fix our image metadata such that the actual and expected locations of Regulus are line up.\n",
    "We can calculate the expected distance from the center of the Sun to Regulus in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulus_pixel = CartesianRepresentation(*eclipse_map.wcs.world_to_pixel(regulus), 0) * u.pix\n",
    "sun_pixel = (\n",
    "    CartesianRepresentation(*eclipse_map.wcs.world_to_pixel(SkyCoord(0 * u.arcsec, 0 * u.arcsec, frame=frame)), 0)\n",
    "    * u.pix\n",
    ")\n",
    "regulus_r = (regulus_pixel - sun_pixel).norm()\n",
    "print(regulus_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "We then use this to find Regulus in our image, by filtering out all pixels which are closer to the Sun than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_x = np.arange(eclipse_map.dimensions[0].value) * u.pix - sun_pixel.x\n",
    "pix_y = np.arange(eclipse_map.dimensions[1].value) * u.pix - sun_pixel.y\n",
    "xx, yy = np.meshgrid(pix_x, pix_y)\n",
    "r = np.sqrt(xx**2 + yy**2)\n",
    "\n",
    "filter_r = regulus_r - (regulus_r / 5)\n",
    "\n",
    "masked = im.copy()\n",
    "masked[r < filter_r] = masked.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Having masked out most of the Sun and its corona, we now find the highest peak remaining, which should be Regulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulus_y, regulus_x = peak_local_max(masked, min_distance=2, num_peaks=1)[0]\n",
    "actual_regulus_pixel = CartesianRepresentation(regulus_x, regulus_y, 0) * u.pix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "We can now compare the identified pixel coordinates of Regulus to the expected coordinates assuming the camera was exactly horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_regulus_pixel)\n",
    "print(regulus_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Finally, we calculate the angular offset between our expected location and our identified location and then add this difference to correct our solar rotation angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_expected = regulus_pixel - sun_pixel\n",
    "vec_actual = actual_regulus_pixel - sun_pixel\n",
    "fudge_angle = -np.arccos(vec_expected.dot(vec_actual) / (vec_expected.norm() * vec_actual.norm()))\n",
    "print(fudge_angle.to(u.deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "We then use this correction factor to build a new `Map` for our image with updated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = make_fitswcs_header(\n",
    "    im,\n",
    "    moon_hpc,\n",
    "    reference_pixel=u.Quantity([im_cx, im_cy]),\n",
    "    scale=u.Quantity([plate_scale, plate_scale]),\n",
    "    rotation_angle=solar_rotation_angle + fudge_angle,\n",
    "    exposure=camera_metadata[\"exposure_time\"],\n",
    "    instrument=camera_metadata[\"camera_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_map = sunpy.map.Map(im, header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Plotting our image again, we now find that the identified location of Regulus and our image line up much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(projection=eclipse_map)\n",
    "eclipse_map.plot(axes=ax, clip_interval=(0, 90) * u.percent)\n",
    "ax.plot_coord(\n",
    "    regulus, \"o\", markeredgewidth=0.5, markeredgecolor=\"w\", markerfacecolor=\"None\", markersize=10, label=\"Regulus\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlim(100, 500)\n",
    "plt.ylim(0, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Combine your Image with NASA Data\n",
    "\n",
    "As mentioned above, one of the main advantages of having data in a `Map` is that it is then easy to combine observations from multiple different sources.\n",
    "Let's overlay an AIA image from the [SDO](https://en.wikipedia.org/wiki/Solar_Dynamics_Observatory) satellite.\n",
    "We'll choose an image that shows extreme ultraviolet emission from the corona, revealing plasma that is around one million degrees.\n",
    "Fortunately, all SDO data is publicly available and SunPy provides a convenient interface for searching for and downloading this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_result = Fido.search(\n",
    "    a.Time(\"2017-08-21 17:27:00\", \"2017-08-21 17:45:00\", eclipse_map.date),\n",
    "    a.Instrument(\"AIA\"),\n",
    "    a.Wavelength(171 * u.Angstrom),\n",
    ")\n",
    "print(aia_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_result[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = Fido.fetch(aia_result[0, 0], site=\"NSO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Having downloaded this data we create a SunPy `Map` and then plot it on top of our eclipse image.\n",
    "Note that despite not being in the same coordinate system, our AIA `Map` is automatically transformed to the coordinate system of our image before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_map = sunpy.map.Map(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = plt.subplot(projection=eclipse_map)\n",
    "eclipse_map.plot(axes=ax)\n",
    "aia_map.plot(axes=ax, autoalign=True)\n",
    "aia_map.draw_grid(axes=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "In this blog post, we demonstrated how to read your eclipse images into a SunPy `Map` and how to combine your own photographs with data from NASA observations of the Sun.\n",
    "Though this post used data from the 2017 eclipse, you should be able to use the same techniques to process your 2024 eclipse observations.\n",
    "Happy eclipse viewing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
